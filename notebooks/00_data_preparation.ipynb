{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8042da6a-f750-434f-b694-f48cf3ed0f54",
   "metadata": {},
   "source": [
    "## 1) Raw File Header Handling\n",
    "NASA POWER hourly exports include a metadata header before the tabular dataset.\n",
    "The preprocessing script scans the raw CSV and locates the first line starting\n",
    "with `YEAR,`, which marks the beginning of the data table. All preceding lines\n",
    "are treated as metadata and skipped.\n",
    "The table itself is comma-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2a8be311-b10e-462f-8c92-2e37adac938e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table starts at line: 10\n",
      "   YEAR  MO  DY  HR  ALLSKY_SFC_SW_DWN    T2M\n",
      "0  2021   1   1   0                0.0  23.35\n",
      "1  2021   1   1   1                0.0  22.70\n",
      "['YEAR', 'MO', 'DY', 'HR', 'ALLSKY_SFC_SW_DWN', 'T2M']\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "raw_path = Path(\"Data/Dataset_phase_1.csv\")\n",
    "\n",
    "# Step 1 — Find the line where the data table starts\n",
    "with raw_path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if line.lstrip().startswith(\"YEAR,\"):\n",
    "            table_start = i\n",
    "            break\n",
    "    else:\n",
    "        raise ValueError(\"Could not find the data table header starting with 'YEAR,'\")\n",
    "\n",
    "print(\"Table starts at line:\", table_start)\n",
    "\n",
    "# Step 2 — Read the table from that line onward (comma-separated)\n",
    "df = pd.read_csv(raw_path, sep=\",\", skiprows=table_start)\n",
    "\n",
    "print(df.head(2))\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de20c15f-ae77-4702-b1fa-2b9a3589fa2d",
   "metadata": {},
   "source": [
    "## 2) Rename columns (keep units honest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c36f606f-7c01-48c2-a632-1485943a60a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['year', 'month', 'day', 'hour', 'ghi_wh_m2', 'temp_c']\n"
     ]
    }
   ],
   "source": [
    "df = df.rename(columns={\n",
    "    \"YEAR\": \"year\",\n",
    "    \"MO\": \"month\",\n",
    "    \"DY\": \"day\",\n",
    "    \"HR\": \"hour\",\n",
    "    \"ALLSKY_SFC_SW_DWN\": \"ghi_wh_m2\",\n",
    "    \"T2M\": \"temp_c\"\n",
    "})\n",
    "\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90546ab-4124-4d09-a70a-cb38c1a21c75",
   "metadata": {},
   "source": [
    "## 3) Creating timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f2d969d0-6f6a-4216-ad8b-b513aa3ec770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day  hour  ghi_wh_m2  temp_c                time\n",
      "0  2021      1    1     0        0.0   23.35 2021-01-01 00:00:00\n",
      "1  2021      1    1     1        0.0   22.70 2021-01-01 01:00:00\n",
      "2  2021      1    1     2        0.0   22.03 2021-01-01 02:00:00\n",
      "3  2021      1    1     3        0.0   21.40 2021-01-01 03:00:00\n",
      "4  2021      1    1     4        0.0   20.78 2021-01-01 04:00:00\n"
     ]
    }
   ],
   "source": [
    "df[\"time\"] = pd.to_datetime(df[[\"year\",\"month\",\"day\"]]) \\\n",
    "             + pd.to_timedelta(df[\"hour\"], unit=\"h\")\n",
    "\n",
    "df = df.sort_values(\"time\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9867384-a937-4ee1-91bd-0097acd53772",
   "metadata": {},
   "source": [
    "## 4) Confirm Temporal Resolution (Hourly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3e102e4f-293d-4281-9a8f-5ded6fafe2fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common temporal step: 0 days 01:00:00\n"
     ]
    }
   ],
   "source": [
    "# Temporal resolution check\n",
    "temporal_step = df[\"time\"].diff().mode()[0]\n",
    "\n",
    "print(\"Most common temporal step:\", temporal_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e97f03d-4471-4dcb-9453-2e099b78f2ff",
   "metadata": {},
   "source": [
    "## 5) Missing Data Percentage (Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "510e1c90-f4d1-4547-aa50-0b6eb10fd9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing GHI values: 1.752%\n",
      "Missing Temperature values: 0.000%\n"
     ]
    }
   ],
   "source": [
    "# replace -999 (NASA POWER uses -999 for missing values\n",
    "df[\"ghi_wh_m2\"] = df[\"ghi_wh_m2\"].replace(-999, pd.NA)\n",
    "df[\"temp_c\"] = df[\"temp_c\"].replace(-999, pd.NA)\n",
    "\n",
    "# computing missing values\n",
    "missing_ghi_pct = df[\"ghi_wh_m2\"].isna().mean() * 100\n",
    "missing_temp_pct = df[\"temp_c\"].isna().mean() * 100\n",
    "\n",
    "print(f\"Missing GHI values: {missing_ghi_pct:.3f}%\")\n",
    "print(f\"Missing Temperature values: {missing_temp_pct:.3f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e634420a-f25f-4244-9907-e8fc11405568",
   "metadata": {},
   "source": [
    "## 6) Missing Timestamps (Gaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aaf3ed5d-b0e6-4457-afb9-e44a9a8c7d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing hourly timestamps: 0.000%\n",
      "Rows: 43824\n"
     ]
    }
   ],
   "source": [
    "full_index = pd.date_range(\n",
    "    start=df[\"time\"].min(),\n",
    "    end=df[\"time\"].max(),\n",
    "    freq=\"h\"\n",
    ")\n",
    "\n",
    "missing_ts_pct = (len(full_index) - len(df)) / len(full_index) * 100\n",
    "\n",
    "print(f\"Missing hourly timestamps: {missing_ts_pct:.3f}%\")\n",
    "print(\"Rows:\", len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7250a154-4959-4f69-af8a-19a85e6c86ce",
   "metadata": {},
   "source": [
    "## 7) Drop missing rows with 1.75% missing GHI and save clean dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fc47c4b6-acbf-4799-8403-78f3caa2dfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned dataset as: Dataset_phase_1_clean.csv\n",
      "Rows: 43056\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Drop missing GHI values (baseline Phase 1 choice)\n",
    "df_clean = df.dropna(subset=[\"ghi_wh_m2\"]).copy()\n",
    "\n",
    "# 2. Keep only the useful columns\n",
    "df_clean = df_clean[[\"time\", \"ghi_wh_m2\", \"temp_c\"]]\n",
    "\n",
    "# 3. Sort chronologically\n",
    "df_clean = df_clean.sort_values(\"time\")\n",
    "\n",
    "# 4. Save in the SAME folder (current directory)\n",
    "df_clean.to_csv(\"Data/Dataset_phase_1_clean.csv\", index=False)\n",
    "\n",
    "print(\"Saved cleaned dataset as: Dataset_phase_1_clean.csv\")\n",
    "print(\"Rows:\", len(df_clean))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
